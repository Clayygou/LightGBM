{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "# pylint: disable = invalid-name, C0111\n",
    "import json\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except BaseException:\n",
    "    import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "# load or create your dataset\n",
    "df_train = pd.read_csv('./binary_data/binary.train', header=None, sep='\\t')\n",
    "df_test = pd.read_csv('./binary_data/binary.test', header=None, sep='\\t')\n",
    "W_train = pd.read_csv('./binary_data/binary.train.weight', header=None)[0]\n",
    "W_test = pd.read_csv('./binary_data/binary.test.weight', header=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df_train[0]\n",
    "y_test = df_test[0]\n",
    "X_train = df_train.drop(0, axis=1)\n",
    "X_test = df_test.drop(0, axis=1)\n",
    "\n",
    "num_train, num_feature = X_train.shape\n",
    "num_train, num_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weight生命每一列的权重，free_raw_data 来重用数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for lightgbm\n",
    "# if you want to re-use data, remember to set free_raw_data=False    重用数据\n",
    "lgb_train = lgb.Dataset(X_train, y_train,\n",
    "                        weight=W_train, free_raw_data=False)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train,\n",
    "                       weight=W_test, free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 验证数据是训练数据，如果没有不显示训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\ttraining's binary_logloss: 0.680298\n",
      "[2]\ttraining's binary_logloss: 0.672021\n",
      "[3]\ttraining's binary_logloss: 0.664444\n",
      "[4]\ttraining's binary_logloss: 0.655536\n",
      "[5]\ttraining's binary_logloss: 0.647375\n",
      "[6]\ttraining's binary_logloss: 0.640788\n",
      "[7]\ttraining's binary_logloss: 0.635012\n",
      "[8]\ttraining's binary_logloss: 0.628454\n",
      "[9]\ttraining's binary_logloss: 0.622423\n",
      "[10]\ttraining's binary_logloss: 0.616808\n",
      "Finished first 10 rounds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\tools\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [21]\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    }
   ],
   "source": [
    "# generate feature names\n",
    "feature_name = ['feature_' + str(col) for col in range(num_feature)]\n",
    "\n",
    "print('Starting training...')\n",
    "# feature_name and categorical_feature\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10,\n",
    "                valid_sets=lgb_train,  # eval training data\n",
    "                feature_name=feature_name,\n",
    "                categorical_feature=[21])\n",
    "print('Finished first 10 rounds...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th feature name is: feature_6\n",
      "Feature names: ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25', 'feature_26', 'feature_27']\n",
      "Feature importances: [8, 4, 0, 19, 8, 36, 3, 0, 2, 10, 5, 1, 0, 9, 5, 3, 0, 2, 2, 5, 1, 0, 35, 3, 28, 45, 31, 35]\n"
     ]
    }
   ],
   "source": [
    "# check feature name\n",
    "print('7th feature name is:', lgb_train.feature_name[6])\n",
    "\n",
    "# feature names\n",
    "print('Feature names:', gbm.feature_name())\n",
    "\n",
    "# feature importances\n",
    "print('Feature importances:', list(gbm.feature_importance()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存成.txt、JSON格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Dumping model to JSON...\n"
     ]
    }
   ],
   "source": [
    "print('Saving model...')\n",
    "# save model to file\n",
    "gbm.save_model('model.txt')\n",
    "\n",
    "print('Dumping model to JSON...')\n",
    "# dump model to JSON (and save to file)\n",
    "model_json = gbm.dump_model()\n",
    "\n",
    "with open('model.json', 'w+') as f:\n",
    "    json.dump(model_json, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model to predict...\n",
      "The rmse of loaded model's prediction is: 0.4618189809505519\n"
     ]
    }
   ],
   "source": [
    "print('Loading model to predict...')\n",
    "# load model to predict\n",
    "bst = lgb.Booster(model_file='model.txt')\n",
    "# can only predict with the best iteration (or the saving iteration)\n",
    "y_pred = bst.predict(X_test)\n",
    "# eval with loaded model\n",
    "print(\"The rmse of loaded model's prediction is:\", mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型保存成.pkl和加载.pkl模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping and loading model with pickle...\n",
      "The rmse of pickled model's prediction is: 0.46989528982016704\n"
     ]
    }
   ],
   "source": [
    "print('Dumping and loading model with pickle...')\n",
    "# dump model with pickle\n",
    "with open('model.pkl', 'wb') as fout:\n",
    "    pickle.dump(gbm, fout)\n",
    "# load model with pickle to predict\n",
    "with open('model.pkl', 'rb') as fin:\n",
    "    pkl_bst = pickle.load(fin)\n",
    "# can predict with any iteration when loaded in pickle way\n",
    "y_pred = pkl_bst.predict(X_test, num_iteration=7)\n",
    "# eval with loaded model\n",
    "print(\"The rmse of pickled model's prediction is:\", mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11]\tvalid_0's binary_logloss: 0.613941\n",
      "[12]\tvalid_0's binary_logloss: 0.610317\n",
      "[13]\tvalid_0's binary_logloss: 0.606257\n",
      "[14]\tvalid_0's binary_logloss: 0.601789\n",
      "[15]\tvalid_0's binary_logloss: 0.597803\n",
      "[16]\tvalid_0's binary_logloss: 0.594579\n",
      "[17]\tvalid_0's binary_logloss: 0.590794\n",
      "[18]\tvalid_0's binary_logloss: 0.58741\n",
      "[19]\tvalid_0's binary_logloss: 0.584296\n",
      "[20]\tvalid_0's binary_logloss: 0.581739\n",
      "Finished 10 - 20 rounds with model file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\tools\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "G:\\tools\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [21]\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "G:\\tools\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    }
   ],
   "source": [
    "# continue training\n",
    "# init_model accepts:\n",
    "# 1. model file name\n",
    "# 2. Booster()\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10,\n",
    "                init_model='model.txt',\n",
    "                valid_sets=lgb_eval)\n",
    "\n",
    "print('Finished 10 - 20 rounds with model file...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置init_model 可以接着上面继续训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21]\tvalid_0's binary_logloss: 0.613941\n",
      "[22]\tvalid_0's binary_logloss: 0.610352\n",
      "[23]\tvalid_0's binary_logloss: 0.60637\n",
      "[24]\tvalid_0's binary_logloss: 0.602024\n",
      "[25]\tvalid_0's binary_logloss: 0.598221\n",
      "[26]\tvalid_0's binary_logloss: 0.595039\n",
      "[27]\tvalid_0's binary_logloss: 0.591429\n",
      "[28]\tvalid_0's binary_logloss: 0.588352\n",
      "[29]\tvalid_0's binary_logloss: 0.585486\n",
      "[30]\tvalid_0's binary_logloss: 0.582613\n",
      "Finished 20 - 30 rounds with decay learning rates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\tools\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "G:\\tools\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:814: UserWarning: The prediction of init_model will be overridden by init_score.\n",
      "  warnings.warn(\"The prediction of init_model will be overridden by init_score.\")\n",
      "G:\\tools\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    }
   ],
   "source": [
    "# decay learning rates\n",
    "# learning_rates accepts:\n",
    "# 1. list/tuple with length = num_boost_round\n",
    "# 2. function(curr_iter)\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10,\n",
    "                init_model=gbm,\n",
    "                learning_rates=lambda iter: 0.05 * (0.99 ** iter),\n",
    "                valid_sets=lgb_eval)\n",
    "\n",
    "print('Finished 20 - 30 rounds with decay learning rates...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过callbacks在训练过程中更改参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\tools\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "G:\\tools\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:814: UserWarning: The prediction of init_model will be overridden by init_score.\n",
      "  warnings.warn(\"The prediction of init_model will be overridden by init_score.\")\n",
      "G:\\tools\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31]\tvalid_0's binary_logloss: 0.613621\n",
      "[32]\tvalid_0's binary_logloss: 0.609283\n",
      "[33]\tvalid_0's binary_logloss: 0.605998\n",
      "[34]\tvalid_0's binary_logloss: 0.601608\n",
      "[35]\tvalid_0's binary_logloss: 0.597791\n",
      "[36]\tvalid_0's binary_logloss: 0.594658\n",
      "[37]\tvalid_0's binary_logloss: 0.59106\n",
      "[38]\tvalid_0's binary_logloss: 0.588155\n",
      "[39]\tvalid_0's binary_logloss: 0.585972\n",
      "[40]\tvalid_0's binary_logloss: 0.584073\n",
      "Finished 30 - 40 rounds with changing bagging_fraction...\n"
     ]
    }
   ],
   "source": [
    "# change other parameters during training\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10,\n",
    "                init_model=gbm,\n",
    "                valid_sets=lgb_eval,\n",
    "                callbacks=[lgb.reset_parameter(bagging_fraction=[0.7] * 5 + [0.6] * 5)])\n",
    "\n",
    "print('Finished 30 - 40 rounds with changing bagging_fraction...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义训练过程中的目标函数 和 验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\tools\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "G:\\tools\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:814: UserWarning: The prediction of init_model will be overridden by init_score.\n",
      "  warnings.warn(\"The prediction of init_model will be overridden by init_score.\")\n",
      "G:\\tools\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41]\tvalid_0's binary_logloss: 4.6809\tvalid_0's error: 0.408\n",
      "[42]\tvalid_0's binary_logloss: 4.49648\tvalid_0's error: 0.404\n",
      "[43]\tvalid_0's binary_logloss: 4.54169\tvalid_0's error: 0.396\n",
      "[44]\tvalid_0's binary_logloss: 4.76092\tvalid_0's error: 0.38\n",
      "[45]\tvalid_0's binary_logloss: 4.7524\tvalid_0's error: 0.384\n",
      "[46]\tvalid_0's binary_logloss: 4.74017\tvalid_0's error: 0.376\n",
      "[47]\tvalid_0's binary_logloss: 4.72303\tvalid_0's error: 0.372\n",
      "[48]\tvalid_0's binary_logloss: 4.71548\tvalid_0's error: 0.366\n",
      "[49]\tvalid_0's binary_logloss: 4.78898\tvalid_0's error: 0.368\n",
      "[50]\tvalid_0's binary_logloss: 5.00385\tvalid_0's error: 0.358\n",
      "Finished 40 - 50 rounds with self-defined objective function and eval metric...\n"
     ]
    }
   ],
   "source": [
    "# self-defined objective function\n",
    "# f(preds: array, train_data: Dataset) -> grad: array, hess: array\n",
    "# log likelihood loss\n",
    "def loglikelihood(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    preds = 1. / (1. + np.exp(-preds))\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1. - preds)\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "# self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, eval_result: float, is_higher_better: bool\n",
    "# binary error\n",
    "def binary_error(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'error', np.mean(labels != (preds > 0.5)), False\n",
    "\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10,\n",
    "                init_model=gbm,\n",
    "                fobj=loglikelihood,\n",
    "                feval=binary_error,\n",
    "                valid_sets=lgb_eval)\n",
    "\n",
    "print('Finished 40 - 50 rounds with self-defined objective function and eval metric...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置多个验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51]\tvalid_0's binary_logloss: 4.6809\tvalid_0's error: 0.408\tvalid_0's accuracy: 0.592\n",
      "[52]\tvalid_0's binary_logloss: 4.49648\tvalid_0's error: 0.404\tvalid_0's accuracy: 0.596\n",
      "[53]\tvalid_0's binary_logloss: 4.54169\tvalid_0's error: 0.396\tvalid_0's accuracy: 0.604\n",
      "[54]\tvalid_0's binary_logloss: 4.76092\tvalid_0's error: 0.38\tvalid_0's accuracy: 0.62\n",
      "[55]\tvalid_0's binary_logloss: 4.7524\tvalid_0's error: 0.384\tvalid_0's accuracy: 0.616\n",
      "[56]\tvalid_0's binary_logloss: 4.74017\tvalid_0's error: 0.376\tvalid_0's accuracy: 0.624\n",
      "[57]\tvalid_0's binary_logloss: 4.72303\tvalid_0's error: 0.372\tvalid_0's accuracy: 0.628\n",
      "[58]\tvalid_0's binary_logloss: 4.71548\tvalid_0's error: 0.366\tvalid_0's accuracy: 0.634\n",
      "[59]\tvalid_0's binary_logloss: 4.78898\tvalid_0's error: 0.368\tvalid_0's accuracy: 0.632\n",
      "[60]\tvalid_0's binary_logloss: 5.00385\tvalid_0's error: 0.358\tvalid_0's accuracy: 0.642\n",
      "Finished 50 - 60 rounds with self-defined objective function and multiple self-defined eval metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\tools\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "G:\\tools\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:814: UserWarning: The prediction of init_model will be overridden by init_score.\n",
      "  warnings.warn(\"The prediction of init_model will be overridden by init_score.\")\n",
      "G:\\tools\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    }
   ],
   "source": [
    "# another self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, eval_result: float, is_higher_better: bool\n",
    "# accuracy\n",
    "def accuracy(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'accuracy', np.mean(labels == (preds > 0.5)), True\n",
    "\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10,\n",
    "                init_model=gbm,\n",
    "                fobj=loglikelihood,\n",
    "                feval=lambda preds, train_data: [binary_error(preds, train_data),\n",
    "                                                 accuracy(preds, train_data)],\n",
    "                valid_sets=lgb_eval)\n",
    "\n",
    "print('Finished 50 - 60 rounds with self-defined objective function '\n",
    "      'and multiple self-defined eval metrics...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过callbacks在训练一定次数加入新的验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new training job...\n",
      "[1]\ttraining's binary_logloss: 0.611255\n",
      "[2]\ttraining's binary_logloss: 0.606714\n",
      "[3]\ttraining's binary_logloss: 0.602329\n",
      "[4]\ttraining's binary_logloss: 0.597525\n",
      "[5]\ttraining's binary_logloss: 0.592888\n",
      "Add a new valid dataset at iteration 5...\n",
      "[6]\ttraining's binary_logloss: 0.588917\tnew_valid's binary_logloss: 0.659461\n",
      "[7]\ttraining's binary_logloss: 0.585157\tnew_valid's binary_logloss: 0.654497\n",
      "[8]\ttraining's binary_logloss: 0.581203\tnew_valid's binary_logloss: 0.649638\n",
      "[9]\ttraining's binary_logloss: 0.577482\tnew_valid's binary_logloss: 0.644992\n",
      "[10]\ttraining's binary_logloss: 0.574196\tnew_valid's binary_logloss: 0.6413\n",
      "Finished first 10 rounds with callback function...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\tools\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    }
   ],
   "source": [
    "print('Starting a new training job...')\n",
    "\n",
    "\n",
    "# callback\n",
    "def reset_metrics():\n",
    "    def callback(env):\n",
    "        lgb_eval_new = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "        if env.iteration - env.begin_iteration == 5:\n",
    "            print('Add a new valid dataset at iteration 5...')\n",
    "            env.model.add_valid(lgb_eval_new, 'new_valid')\n",
    "    callback.before_iteration = True\n",
    "    callback.order = 0\n",
    "    return callback\n",
    "\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10,\n",
    "                valid_sets=lgb_train,\n",
    "                callbacks=[reset_metrics()])\n",
    "\n",
    "print('Finished first 10 rounds with callback function...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
